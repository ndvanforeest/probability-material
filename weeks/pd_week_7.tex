% arara: pdflatex: { shell: yes }
% arara: pythontex: {verbose: yes, rerun: always }
% arara: pdflatex: { shell: yes }

\input{header}

\title{Probability Distributions, Week 7}

\begin{document}
\maketitle
\toccontents


\section{Lecture 13}

\subsection{Compulsary material}
\label{sec:compulsary-material}



\begin{itemize}
\item 10.3: read
\item BH video: 30
\end{itemize}


\begin{pycode}
from pathlib import Path

exercise_name = "bh-10.23.tex"
fname = Path("../bh_problems") / exercise_name
with fname.open("r") as fp:
    state = 0  # dump
    for line in fp.readlines():
        if line[:16] == r"\begin{exercise}":
            state = 1
        if state == 1:
            print(line.strip())
        if line[:14] == r"\end{exercise}":
            break
\end{pycode}


\begin{pycode}
from pathlib import Path

exercise_name = "bh-10.26.tex"
fname = Path("../bh_problems") / exercise_name
with fname.open("r") as fp:
    state = 0  # dump
    for line in fp.readlines():
        if line[:16] == r"\begin{exercise}":
            state = 1
        if state == 1:
            print(line.strip())
        if line[:14] == r"\end{exercise}":
            break
\end{pycode}



\begin{exercise}
A shop receives demands with sizes $\{X_{k}\}$ for some product, for instance, cans with beans.
Write $\mu = \E X$ and $\sigma^{2} = \V X$.
Suppose $n$ customers arrive so that the total demand $D=\sum_{i=1}^{n} X_{i}$.
The shop has an initial inventory of $I$ cans on the shelf.
\begin{enumerate}[a.]
\item Use the CLT to determine $I$ such that the probability that the total demand~$D$ remains below $I$ is larger than some threshold $\alpha$.
\item The safety stock is defined as $I$ minus the expected demand. How large is the safety stock?
\item When is it reasonable to use the CLT to estimate $I$?
\end{enumerate}
\begin{solution}
We have $D=\sum_{i=1}^{n} X_{i}$. Hence, $\E D = n \E X = n \mu$ and $\V D = n \V X = n \sigma^{2}$. We search for $I$ such that
\begin{equation}
  \label{eq:131}
\alpha = \P{D \leq I}   = \P{\bar D_n \leq \bar I_{n}},
\end{equation}
where
\begin{align}
  \label{eq:132}\
\bar D_{n} &:= \frac{D-n\mu}{\sigma \sqrt n}   = \frac{D/n - \mu}{\sigma/\sqrt n}, &
\bar I_{n} &:= \frac{I-n\mu}{\sigma \sqrt n}   = \frac{I/n - \mu}{\sigma/\sqrt n}.
\end{align}
Hence, by the CLT, $\bar D_{n}\sim \Norm{0, 1}$ if $n$ large. Thus, we need to find $I$ such that
\begin{align}
\P{\bar D_{n} \leq \bar I_{n}} &= \Phi(\bar I_{n}) = \alpha \implies \bar I_{n} = \Phi^{-1}(\alpha) \\
&\implies  I = n\mu + \sigma \sqrt n \Phi^{-1}(\alpha).
\end{align}
Once we found $I$, the safety stock is $I-n\mu$.

Of course, `reasonable' is an imprecise concept.
But we are tempted to say that it is reasonable to use the CLT to estimate the distribution of $D$ when we need more than a few customers to empty the stock.
Hence, when $I/\mu \geq 10$, then the CLT already performs reasonably well to estimate the tail probability $\P{D>I}$.

An interesting extension is to suppose that the number of customers is Poisson distributed. Then we need Eve's law to determine $\V D$.

\end{solution}
\end{exercise}



\subsection{Background material, not compulary}
\label{sec:backgr-mater-not}

The next couple of exercises concentrate on the interpretation of expectation when dealing with real money, not just toy examples like throwing dice.
We use this insight in the next lecturexto explain why people pay for insurance, even though they have a negative expected value due to the payments to the insurance company.

\begin{exercise}
Suppose we have one perfectly fair die.
When the die lands 1 or 2 you loose your investment, otherwise your investment gets doubled.
You are given two options: bet all the money $M$ you have and whatever you can lay your hands on (possibly including the total fortune of your parents, your friends, and so on), or not bet at all.
Show that your expected gain is $M/3$.
Given this, would you play this game?
\begin{solution}
You invest $M$. When you win, you receive  $2M$, otherwise you loose your investment. Hence, your expected gain is $2 M\cdot 4/6 - M = M/3 > 0$.
As E.T.
Jaynes puts it: `It seemed obvious to Bernoulli, as it doubtless does also to the reader, that nobody in his right mind would really choose the first alternative.
This means that our common sense, in some cases, rejects the criterion of maximizing expected profit.'
\end{solution}
\end{exercise}

\begin{exercise}
You are given two options: bet any amount of  money you like on the basis that with probability $p=10^{-6}$ you win  $1 000 001$ times what you wagered, but with probability $1-p$ you loose all.
Would you bet all the money you have?
\begin{solution}
  Of course not.
  Loosing all you have is much worse than your increased happyness when your fortune gets doubled.
  One way to model this effect is to assign a `utility' to your money.
  A particular model is then to assign a utility of $\log m$ to an amount of money $m$. Then the  utility of doubling is $\log(2m)$ while loosing it all is $\log 0 = -\infty$.
\end{solution}
\end{exercise}

\begin{exercise}
Consider the, so-called, St.~Petersburg game in which we throw a fair coin until it comes up heads, and then we stop.
When the coin lands heads on the $n$th throw, you receive $2^{n}$ Euros.
Suppose you pay $f=5$ euros to play this game.
If the coin lands heads on the first throw, you earn $2-5=-3$ euros.
If it lands tails first, and then heads, you earn $2^{2}-5=-1$.
If you throw $TTH$, then you earn $2^{3}-5=3$, and so on.
More generally, suppose your initial capital is $m$ and you invest $f$ to play the game, then your expected gain is
\begin{equation}
m-f + \sum_{n=1}^{\infty} 2^{-n} 2^{n} = \infty.
\end{equation}


But, how much are you actually prepared to pay to enter this game, given that you can also lose part of your investment $f$?
To resolve this, we don't focus on monetary expectation but instead on expected utility where we express the utility of having $x$ euro as $\log x$ (so, the utility of $10^{6}$ is twice has much as the utility of $10^{3}$).
Explain that, when investing $f$, the expected utility is given by
\begin{equation}
  \label{eq:135}
  \sum_{n=1}^{\infty} 2^{-n}\log(m - f + 2^{n}).
\end{equation}
\begin{solution}
This game comes with an interesting story,  check Wikipedia.

Clearly, you can easily loose most of your investment $f$, but potentially you can earn a lot. We are therefore in same setting as the previous exercise.

Suppose you have a capital $m$ to which you assign a utility $\log m$.
The expected utility follows right away from LOTE,
because right after paying $f$ your capital is $m-f$, and when the $n$th throw is the first time heads turns up, your capital becomes $m-f+2^{n}$.
Then take the log to convert this capital to utility, and take the expectation.
\end{solution}
\end{exercise}


\begin{exercise}
For $m=200$, write a computer program to compute $f'$ such that
\begin{equation}
  \label{eq:136}
\log m =  \sum_{n=1}^{\infty} 2^{-n}\log(m - f' + 2^{n}).
 \end{equation}
What is the interpretation of this $f'$?
\begin{solution}
%  This $f'$ is a breakpoint.
  If you don't play the game, your utility is the LHS, i.e. $\log m$.
  If you pay $f$ to enter the game, your expected utility is given by the RHS.
  For an investment $f'$ both sides are equal, so your utility is the same in either case.
  When you can enter the game by paying $f<f'$, you should play the game, if you think that the $\log$ function models your utility).


  To find $f'$ we use bi-section.
  We assume that the function $g$ is increasing, and $g(a) \leq 0 \leq g(b)$.
  This implementation aims at showing you the algorithm.
  Don't use it for real problems.
  There are better algorithms (although based on the same principles), and they include necessary tests on whether the conditions on $g$ are met.

\begin{samepage}
\begin{pyblock}
def find_root(g, a, b, eps=1e-3):
    while b - a > eps:
        mid = (a + b) / 2
        print(f"a = {a}, mid = {mid}, b = {b}\n")
        if g(mid) > 0:
            b = mid
        else:
            a = mid
    return (a + b) / 2
\end{pyblock}
\end{samepage}


Let' apply it to finding the root of the function $x\to x-5.5$.
(It's useful but not necessary that you read about the anonymous function \texttt{lambda }in python.)
Study the output carefully.
It is important that you understand how bisection works.
\begin{pyblock}
print(find_root(lambda x: x - 5.5, 0, 10.19027301723047810283))
\end{pyblock}

\printpythontex

\begin{samepage}

Now apply it to our gain, and think hard about the sign of the gain function. We want it such that it is $<0$ for $f=0$ and $>0$ for $f\gg 0$.
\begin{pyblock}
from math import log

m = 200

def gain(f):
    return log(m) - sum(log(m - f + 2 ** n) / 2 ** n for n in range(1, 100))


print(find_root(gain, 0, 200))
\end{pyblock}

\end{samepage}

\printpythontex

\end{solution}
\end{exercise}



\section{Lecture 14}

\subsection{Compulsary material}
\label{sec:compulsary-material}



\begin{itemize}
\item 10.4: read
\item BH video: -
\end{itemize}



\begin{pycode}
from pathlib import Path

exercise_name = "bh-10.28.tex"
fname = Path("../bh_problems") / exercise_name
with fname.open("r") as fp:
    state = 0  # dump
    for line in fp.readlines():
        if line[:16] == r"\begin{exercise}":
            state = 1
        if state == 1:
            print(line.strip())
        if line[:14] == r"\end{exercise}":
            break
\end{pycode}


\begin{pycode}
from pathlib import Path

exercise_name = "bh-10.36.tex"
fname = Path("../bh_problems") / exercise_name
with fname.open("r") as fp:
    state = 0  # dump
    for line in fp.readlines():
        if line[:16] == r"\begin{exercise}":
            state = 1
        if state == 1:
            print(line.strip())
        if line[:14] == r"\end{exercise}":
            break
\end{pycode}



\begin{exercise}
Little Mike needs to get ready for school.
He must leave within 15 minutes, but there are two more things he needs to do: eat his breakfast and get dressed.
The time $XS$ it takes Mike to eat his breakfast has a mean value of 6 minutes with a standard deviation of 3 minutes.
The time $Y$ it takes Mike to get dressed has a mean value of 4 minutes with a standard deviation of 1 minute.
Assume that $X$ and $Y$ are independent.


Give a lower bound for the probability that Mike will be ready for school in time.
\begin{solution}
Let $X$ and $Y$ denote the time it takes Mike to eat his breakfast and get dressed, respectively. Let $Z = X + Y$ denote the total time Mike needs to finish his morning routine. Let $\mu$ denote the mean of $Z$, i.e., $\mu = \E{Z} = \E{X+Y} = 6+4 = 10$. Then,
\begin{align}
    \P{Z < 15} = 1 - \P{Z \geq 15},
\end{align}
where, using Chebyshev's inequality,
\begin{align}
  \P{Z \geq 15} &= \P{Z - \mu \geq 5} \\
  &\leq \P{|Z - \mu| \geq 5} \\
  &\leq \frac{\V{Z}}{5^2} \\
  &= \frac{\V{X} + \V{Y}}{25} \\
  &= \frac{9 + 1}{25} \\
  &= 10/25 = 0.4.
\end{align}
Hence,
\begin{align}
    \P{Z < 15} \geq 1 - 0.4 = 0.6.
\end{align}
So the probabilty that Mike will be ready in time is at least 60\%.

Why can't we use the CLT here?
First of all, the CLT holds in the limit; a sum of two independent rvs does not really represent a sum over many independent rvs.
Second, it is not given that $X$ and $Y$ are normally distributed, we just know the mean and variances.
\end{solution}
\end{exercise}


\subsection{Background material, not compulary}
\label{sec:backgr-mater-not}


\begin{exercise}
Suppose you pay a premium $P$ to an insurance company to be protected against a random loss $L \in \{L_{i}, i \leq n\}$ occurring with probability $\P{L = L_{i}} = p_{i}$.
Since insurance companies are very large, their utility is nearly linear in the range of $L_{i}$.
Assume your utility function for money is the log function and you have an initial amount $M$ of money.
Explain that you and the insurance company are willing to do business when the premium $P$ satisfies
\begin{equation}
  \label{eq:1313-7}
\E L < P <   M - \exp\left(\E{\log (M-L)}\right).
\end{equation}
\begin{solution}

As the potential losses $L_{i}$ are relativey small for  the insurance company, their expected gain is $P-\E L$. When this is positive, the insurance company is happy.

If you don't take the insurance, your utility is  $\sum_{i=1}^{n} p_{i} \log (M-L_{i}) = \E{\log(M-L)}$, while if you do take the insurance and pay $P$, your utility is $\log(M-P)$. So by taking the insurance, your gained utility is
\begin{equation}
  \label{eq:138}
\log(M-P) - \E{\log(M-L)}.
\end{equation}
For this gain to be  positive we need that $P$ is such that
\begin{equation}
  \label{eq:139}
M-P > \exp\left(\E{\log(M-L)}\right).
\end{equation}
The RHS in \cref{eq:1313-7} follows now immediately.
\end{solution}
\end{exercise}


\begin{exercise}
Use the Taylor series of $\log (1-x) \approx x + x^{2}/2$ and $e^{x} \approx 1+x $  to see that when $M$ quite a bit larger than $\E L$ that
\begin{equation}
  \label{eq:137}
M - \exp\left(\E{\log (M-L)}\right) \approx \E L + \frac{\V L}{2 M} + \cdots
\end{equation}
Interpret the result.
\begin{solution}
  \begin{align}
M - \exp\left(\E{\log (M-L)}\right)
&=  M - \exp\left(\E{\log M + \log (1-L/M)}\right)  \\
&=  M - \exp\left(\log M + \E{\log (1-L/M)}\right)  \\
&=  M - M \exp\left(\E{\log (1-L/M)}\right)  \\
&\approx  M - M \exp\left(\E{ L/M + L^{2}/2M^{2}}\right)  \\
&=  M - M \exp\left(\E{L}/M + \E{L^{2}}/2M^{2}\right)  \\
&\approx  M - M \left(1+ \E{L}/M + \E{L^{2}}/2M^{2}\right)  \\
&= \E L  + \frac{\E{L^{2}}}{2M} \\
&= \E L + \frac{\V{L}}{2M} + \frac{(\E{L})^{2}}{2M}.
  \end{align}

  In words, when the premium $P>\E L$, the insurance company is interested.
  And when $P< \E L + \V{L}/2M$, you might be interested as the insurance protects you against the \emph{variability} of the loss.

\end{solution}
\end{exercise}


\section{Tutorial}
\label{sec:tutorial}


\subsection{Practice}

We consider the height of a certain population of people (e.g., all students at the University of Groningen). For some reason, we don't know the value of the mean $\mu$ of the population, but we do know that the standard deviation $\sigma$ is 10 cm. We use the sample mean $\bar{X}_n$ of an i.i.d. sample $X_1, \ldots, X_n$, from the population (measured in cm) to estimate the true mean $\mu$.  We want to choose the sample size $n$ in such a way that our estimate $\bar{X}_n$ is sufficiently reliable.

\begin{exercise}
One measure of reliability of our estimator $\bar{X}_n$ is its standard deviation. Let's say we find our estimator reliable if its standard deviation is at most 1 cm. Give a lower bound for $n$ for which we can guarantee that our esitmator is reliable in this sense.
\begin{solution}
We want to guarante that $sd(\bar{X}_n) \leq 1$, which is equivalent to $\V{\bar{X}_n} \leq 1$. We have
\begin{align}
    \V{\bar{X}_n} &= \V{\frac{1}{n}\sum_{i=1}^n X_i} \\
    &= \frac{1}{n^2} \sum_{i=1}^n \V{X_i} \\
    &= \frac{1}{n^2} \cdot n \cdot \sigma^2 \\
    &= \frac{100}{n}.
\end{align}
So to guarantee we have a reliable estimator, we need $\frac{100}{n} \leq 1$, which is equivalent to $n \geq 100$.
\end{solution}
\end{exercise}

\begin{exercise}
Another measure of reliability of our estimator is given by the probability that our estimate is very bad. Specifically, we say our estimate is reliable if we can be 99\% sure that our estimate is off by less than 5 cm. Give a lower bound for $n$ for which we can guarantee that our estimator is reliable in this sense.
\begin{solution}
We need to guarantee that
\begin{align}
    \P{| \bar{X}_n - \mu | \leq 5} \geq 0.99,
\end{align}
which is equivalent to
\begin{align}
    \P{| \bar{X}_n - \mu | > 5} < 0.01,
\end{align}
Note that $\bar{X}_n$ is a random variable with mean $\mu$ and variance $\sigma^2/n = 100/n$. Using Chebyshev's inequality, we obtain
\begin{align}
    \P{| \bar{X}_n - \mu | > 5} &< \frac{100/n}{5^2} = 4/n.
\end{align}
Equating the right-hand side to 0.01 yields $n=400$. So we need $n \geq 400$.
\end{solution}
\end{exercise}


\subsection{BH Exercises}

\begin{pycode}
from pathlib import Path

exercise_name = "bh-10.39.tex"
fname = Path("../bh_problems") / exercise_name
with fname.open("r") as fp:
    state = 0  # dump
    for line in fp.readlines():
        if line[:16] == r"\begin{exercise}":
            state = 1
        if state == 1:
            print(line.strip())
        if line[:14] == r"\end{exercise}":
            break
\end{pycode}

\section{Homework}
\label{sec:homework}

\subsection{Practice}
\label{sec:practice}

We shoot an arrow at a target. We aim at the center of the target. Our aim is not perfect though. We model our horizontal and vertical deviation from the target (in inches) by two independent standard normal random variables $X$ and $Y$, respectively. (So $X<0$ if we shoot to far to the left, for example.)

\begin{exercise}
Compute the density function of the (Euclidean) distance from our arrow to the center of the target. %Compare the result to the pdf of a standard normal random variable.
\begin{solution}
Let $W$ denote the distance in question. That is, $W = \| (X,Y) \|_2 = \sqrt{X^2 + Y^2}$. Write $V = X^2 + Y^2$. Then, $V$ has a $\chi^2_2$ distribution and $W = \sqrt{V}$. Note that for $v \geq 0$, the function $w = g(v) = \sqrt{v}$ is invertible, with $v = g^{-1}(w) = w^2$. Hence, using the pdf of a $\chi^2_2$ distribution and the change of variables technique from chapter 8, we obtain
\begin{align}
    f_W(w) &=  |\frac{dv}{dw}| f_V(v) \\
    &= 2w f_V(w^2) \\
    &= 2w \frac{1}{2} e^{-(w^2)/2} \\
    &= w e^{-(w^2)/2},
\end{align}
for $w \geq 0$.
\end{solution}
\end{exercise}


\begin{exercise}
What is the expected distance from the center of the target?
\begin{solution}

Let $s = w^2/2$ and $w = \sqrt{2s}$
We have
\begin{align}
    \E{W} &= \int_{0}^{\infty} w w e^{-(w^2)/2} dw \\
    &= \int_{0}^{\infty} \sqrt{2s} e^{-s} ds \\
    &= \sqrt{2}\int_{0}^{\infty} s^{\frac{3}{2}-1} e^{-s} ds \\
    &= \sqrt{2}\Gamma\big(\frac{3}{2}\big) \\
    &= \sqrt{2} \frac{1}{2}\Gamma\big(\frac{1}{2}\big) \\
    &= \sqrt{\frac{\pi}{2}}.
\end{align}
So $\E{W} = \sqrt{\frac{\pi}{2}}$.
\end{solution}
\end{exercise}

Last week I stepped in dog poo two days in a row. This annoyed me and I decided that if the same happens to me again more than 5 times in the next 50 days, I will move to a neighbourhood with a lower dog population density.

\begin{exercise}
Suppose that the probability I step in dog poo on a given day is 5\%. Moreover, assume that the days are independent. Use a central limit theorem-based approximation to approximate the probability that I will decide to move as a result of the dog poo situation. (You may ignore the continuity correction.)
\begin{solution}
Define $Y_n$ as the number of times I step in dog poo in $n$ subsequent days. Then, $Y_n \sim \text{Bin}(n, p)$, where $n=50$ and $p = 0.05$. By the Normal approximation of the Binomial distribution, we have approximately
\begin{align}
    Y_n \sim \mathcal{N}(np, np(1-p)).
\end{align}
Let $Z \sim \mathcal{N}(0,1)$. Then, for the probability that I will move we get
\begin{align}
    \P{Y_n > 5} &= \P{\frac{Y_n - np}{\sqrt{np(1-p)}} > \frac{5 - np}{\sqrt{np(1-p)}} } \\
    &\approx \P{Z > \frac{5 - 50\cdot 0.05}{\sqrt{50 \cdot 0.05 \cdot 0.95}} } \\
    &= \P{Z > \frac{2.5}{\sqrt{2.375}} } \\
    &= 1 - \Phi(\frac{2.5}{\sqrt{2.75}}) =  1 - 0.9473 = 0.0527.
\end{align}
So the probability I will move is approximately 5.3\%.
\end{solution}
\end{exercise}


\subsection{BH Exercises}
\label{sec:bh-exercises-1}


\begin{pycode}
from pathlib import Path

exercise_name = "bh-10.30.tex"
fname = Path("../bh_problems") / exercise_name
with fname.open("r") as fp:
    state = 0  # dump
    for line in fp.readlines():
        if line[:16] == r"\begin{exercise}":
            state = 1
        if state == 1:
            print(line.strip())
        if line[:14] == r"\end{exercise}":
            break
\end{pycode}



% \section{Polleverywhere questions}
% \label{sec:polev-quest}


% TBD


\section{True false questions}
\label{sec:true-false-questions}
\setcounter{theorem}{0}
\subfile{../truefalse/tf-week-7-source-questions.tex}


\section{Assignment}
\label{sec:assignment}

No assignment this week.

\opt{all-solutions-at-end}{
\Closesolutionfile{hint}
\Closesolutionfile{ans}
\clearpage
\section{Hints}
\input{hint}
\clearpage
\section{Solutions}
\input{ans}
}
\end{document}
